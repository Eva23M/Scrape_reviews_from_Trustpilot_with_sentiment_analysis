# -*- coding: utf-8 -*-
"""5400_assignment2_wenhui_ma.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IHKrEF5f0z0kv7u_K0VAc6juW1ju9hd1
"""

import numpy as np
import pandas as pd
!pip install -U sklearn
from sklearn.model_selection import train_test_split

filepath = '/content/reviews.csv'
raw_data = pd.read_csv(filepath, delimiter='\t')

test_data = raw_data[['RatingValue','Review']]

sentiment = []

for i in range(len(test_data)):
  if int(test_data['RatingValue'][i]) == 1 or int(test_data['RatingValue'][i]) == 2:
    sentiment.append(0)  
  elif int(test_data['RatingValue'][i]) == 3:
    sentiment.append(1)  
  else:
    sentiment.append(2)

test_data['Sentiment'] = sentiment

data = test_data[['Sentiment','Review']]

data['Sentiment'].value_counts()

new_data = data.drop(data.query('Sentiment == 2').sample(frac=.9).index)

data1 = new_data.drop(new_data.query('Sentiment == 1').sample(frac=.5).index)

data1.reset_index(drop=True)

data1['Sentiment'].value_counts()

# splict dataset
train_data, valid_data = train_test_split(data1, test_size=0.15, random_state=42)

# save as csv file
train_data.to_csv('train.csv')
valid_data.to_csv('valid.csv')

data_train = pd.read_csv('/content/train.csv')
data_valid = pd.read_csv('/content/valid.csv')

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
import nltk
nltk.download('stopwords')
from nltk.stem.snowball import SnowballStemmer

stemmer = SnowballStemmer("english", ignore_stopwords=True)
class StemmedCountVectorizer(CountVectorizer):
    def build_analyzer(self):
        analyzer = super(StemmedCountVectorizer, self).build_analyzer()
        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])
stemmed_count_vect = StemmedCountVectorizer(stop_words='english')

text_clf = Pipeline([
    ('vect', stemmed_count_vect),
    ('tfidf', TfidfTransformer()),
    ('clf', MultinomialNB()),
])

text_clf.fit(data_train['Review'], data_train['Sentiment'])

nb_predicted = text_clf.predict(data_valid['Review'])
np.mean(nb_predicted == data_valid['Sentiment'])

# try sgd
from sklearn.linear_model import SGDClassifier
text_clf2 = Pipeline([
    ('vect', stemmed_count_vect),
    ('tfidf', TfidfTransformer()),
    ('clf', SGDClassifier(loss='hinge', penalty='l2',
                          alpha=1e-3, random_state=42,
                          max_iter=5, tol=None)),
])

text_clf2.fit(data_train['Review'], data_train['Sentiment'])
sgd_predicted = text_clf2.predict(data_valid['Review'])
np.mean(sgd_predicted == data_valid['Sentiment'])

from sklearn import metrics
from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix
print(metrics.classification_report(data_valid['Sentiment'], nb_predicted))

print('Accuracy: ',accuracy_score(data_valid['Sentiment'], nb_predicted))

f1 = f1_score(data_valid['Sentiment'], nb_predicted,average='weighted')
print('F1 Score: ',f1)

print('Confusion Matrix: ')
cm = confusion_matrix(data_valid['Sentiment'], nb_predicted)
print(confusion_matrix(data_valid['Sentiment'], nb_predicted))

import matplotlib.pyplot as plt  
label = ['negative','neutral','positive']
fig = plt.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(cm)
plt.title('Confusion matrix of MultinomialNB')
fig.colorbar(cax)
ax.set_xticklabels([''] + label)
ax.set_yticklabels([''] + label)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()